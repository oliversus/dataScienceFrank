{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (the easy way)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll cheat by using sklearn.naive_bayes to train a spam classifier! Most of the code is just loading our training data into a pandas DataFrame that we can play with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import numpy\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def readFiles(path):\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            path = os.path.join(root, filename)\n",
    "\n",
    "            inBody = False\n",
    "            lines = []\n",
    "            f = io.open(path, 'r', encoding='latin1')\n",
    "            for line in f:\n",
    "                if inBody:\n",
    "                    lines.append(line)\n",
    "                elif line == '\\n':\n",
    "                    inBody = True\n",
    "            f.close()\n",
    "            message = '\\n'.join(lines)\n",
    "            yield path, message\n",
    "\n",
    "\n",
    "def dataFrameFromDirectory(path, classification):\n",
    "    rows = []\n",
    "    index = []\n",
    "    for filename, message in readFiles(path):\n",
    "        rows.append({'message': message, 'class': classification})\n",
    "        index.append(filename)\n",
    "\n",
    "    return DataFrame(rows, index=index)\n",
    "\n",
    "data = DataFrame({'message': [], 'class': []})\n",
    "\n",
    "data = data.append(dataFrameFromDirectory('/home/osus/workspace/SPAMFilter/sus/oliver/DataScience/SPAM/', 'spam'))\n",
    "data = data.append(dataFrameFromDirectory('/home/osus/workspace/SPAMFilter/sus/oliver/DataScience/HAM/', 'ham'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at that DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/home/osus/workspace/SPAMFilter/sus/oliver/DataScience/SPAM/SPAM4.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>We are here to help you to design your stands ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/osus/workspace/SPAMFilter/sus/oliver/DataScience/SPAM/SPAM2.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your order has been successfully processed \\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/osus/workspace/SPAMFilter/sus/oliver/DataScience/SPAM/SPAM1.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>PLANT CELL BIOTECHNOLOGY AND MOLECULAR BIOLOGY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/osus/workspace/SPAMFilter/sus/oliver/DataScience/SPAM/SPAM3.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>Academic English Language Editing\\n\\nAcademic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/home/osus/workspace/SPAMFilter/sus/oliver/DataScience/SPAM/SPAM5.txt</th>\n",
       "      <td>spam</td>\n",
       "      <td>International Journal of Plant &amp; Soil Science\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   class  \\\n",
       "/home/osus/workspace/SPAMFilter/sus/oliver/Data...  spam   \n",
       "/home/osus/workspace/SPAMFilter/sus/oliver/Data...  spam   \n",
       "/home/osus/workspace/SPAMFilter/sus/oliver/Data...  spam   \n",
       "/home/osus/workspace/SPAMFilter/sus/oliver/Data...  spam   \n",
       "/home/osus/workspace/SPAMFilter/sus/oliver/Data...  spam   \n",
       "\n",
       "                                                                                              message  \n",
       "/home/osus/workspace/SPAMFilter/sus/oliver/Data...  We are here to help you to design your stands ...  \n",
       "/home/osus/workspace/SPAMFilter/sus/oliver/Data...  Your order has been successfully processed \\n\\...  \n",
       "/home/osus/workspace/SPAMFilter/sus/oliver/Data...  PLANT CELL BIOTECHNOLOGY AND MOLECULAR BIOLOGY...  \n",
       "/home/osus/workspace/SPAMFilter/sus/oliver/Data...  Academic English Language Editing\\n\\nAcademic ...  \n",
       "/home/osus/workspace/SPAMFilter/sus/oliver/Data...  International Journal of Plant & Soil Science\\...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use a CountVectorizer to split up each message into its list of words, and throw that into a MultinomialNB classifier. Call fit() and we've got a trained spam filter ready to go! It's just that easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "counts = vectorizer.fit_transform(data['message'].values)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "targets = data['class'].values\n",
    "classifier.fit(counts, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam', 'ham'], \n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = ['Order is Pending', \"Hi Bob, how about a game of golf tomorrow?\"]\n",
    "example_counts = vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is small, so our spam classifier isn't actually very good. Try running some different test emails through it and see if you get the results you expect.\n",
    "\n",
    "If you really want to challenge yourself, try applying train/test to this spam classifier - see how well it can predict some subset of the ham and spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
